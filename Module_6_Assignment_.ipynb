{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning: Mastering Neural Networks - Module 6 Assignment: Deep Convolutional Generative Adverserial Networks (DCGAN)\n",
        "\n",
        "In this assignment, we will take a look at an implementation of Deep Convolutional Generative Adverserial Networks (DCGAN). GANs were first introduced in the following paper: and have been a very exciting implementation of deep neural networks. Pytorch provides example code for implementing DCGANs and a tutorial is provided here. For this assignment we have adapted the code in the tutorial.\n",
        "\n",
        "Your task in this assignment will be to train Discriminator and Generator networks to create new Flowers based on the Oxford102Flowers dataset that is available in PyTorch. Since we have not shown an example of training a GAN before, skeleton code will be provided!\n",
        "\n",
        "Note: training these GANs for 100 Epochs takes ~15min on a GPU enabled Colab notebook."
      ],
      "metadata": {
        "id": "aZVJ8gUn1RR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.datasets\n",
        "import torchvision.utils as vutils\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.modules.flatten import Flatten\n",
        "import time, copy\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# device config (train our model on GPU if it is available which is much faster)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "PgHgzEgcFzdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These transforms will be performed on every datapoint - in this example we want to transform every\n",
        "# datapoint to a Tensor datatype, and perform normalization\n",
        "image_size = 64\n",
        "transform = transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ])\n",
        "\n",
        "flowers_train = torchvision.datasets.Flowers102('', split = \"train\", transform =transform, download=True)"
      ],
      "metadata": {
        "id": "LlbVuSs5Fvcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will create DataLoaders with a batch size of 102, allowing us to use 10 batches per Epoch\n",
        "batch_size = 102\n",
        "dataloaders = {'train': DataLoader(flowers_train, batch_size=batch_size)}\n",
        "\n",
        "dataset_sizes = {'train': len(flowers_train)}\n",
        "print(f'dataset_sizes = {dataset_sizes}')"
      ],
      "metadata": {
        "id": "cWHFv3GSJ_B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Visualization\n",
        "\n",
        "Here we will visualize a grid of sample of our datasets. You can see that there are multiple pictures of each type of flower."
      ],
      "metadata": {
        "id": "S4qd0vJ-KLmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization function borrowed from: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloaders[\"train\"]))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "id": "iL0Jf6ISKdgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Models\n",
        "\n",
        "The Generator and Discriminator networks are alot more complex than a standard CNN. Below we have defined some network parameters that are given in the original paper and the PyTorch tutorial."
      ],
      "metadata": {
        "id": "fFAJzkrCeSw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64"
      ],
      "metadata": {
        "id": "siAW9RuXRRrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add the activation functions into the models!\n",
        "# You should add a LeakyRelu that operates in place with a negative slope of 0.2\n",
        "# for every activation function in the discriminator EXCEPT the last one, which\n",
        "# should be a Sigmoid\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.pipeline = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.pipeline(input)\n",
        "\n",
        "# For the generator, you should use regular ReLU functions that operate in place\n",
        "# for all of the activation functions except for the last one, which should be\n",
        "# a TanH\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nc, nz, ngf):\n",
        "        super(Generator, self).__init__()\n",
        "        self.pipeline = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>,\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            # TODO: Activation function\n",
        "            <your_code_here>\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.pipeline(input)"
      ],
      "metadata": {
        "id": "mcYK-Dt-UkjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "# This function initializes the weights of certain layers according to the distributions described in the original paper\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "2sgF9uCPUOTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create the Discriminator and Generator (and send to device)\n",
        "netD =\n",
        "netG =\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)\n",
        "print(netG)"
      ],
      "metadata": {
        "id": "RKPnLkykUpkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Models\n",
        "\n",
        "This is training loop is much different than ones we have used in the past and is specialized to train GANs. We will train on our entire training set and leave no images for validation or testing as we are interested in showing our model as much data as possible to improve the Generative capabilities."
      ],
      "metadata": {
        "id": "X0dFrZsdeL4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training adapted from: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "def train_GANS(netD, netG, dataloaders, dataset_sizes, criterion, optimizerD, optimizerG, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Keep track of how loss and accuracy evolves during training\n",
        "    training_curves = {}\n",
        "    training_curves['G'] = []\n",
        "    training_curves['D'] = []\n",
        "    phase = 'train'\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for _, inputs in enumerate(dataloaders[phase], 0):\n",
        "\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            ## Train with all-real batch\n",
        "            optimizerD.zero_grad()\n",
        "            # Format batch\n",
        "            real_cpu = inputs[0].to(device)\n",
        "            b_size = real_cpu.size(0)\n",
        "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "            # Forward pass real batch through D\n",
        "            output = netD(real_cpu).view(-1)\n",
        "            # Calculate loss on all-real batch\n",
        "            errD_real = criterion(output, label)\n",
        "            # Calculate gradients for D in backward pass\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            ## Train with all-fake batch\n",
        "            # Generate batch of latent vectors\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            # Generate fake image batch with G\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "            # Classify all fake batch with D\n",
        "            output = netD(fake.detach()).view(-1)\n",
        "            # Calculate D's loss on the all-fake batch\n",
        "            errD_fake = criterion(output, label)\n",
        "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            # Compute error of D as sum over the fake and the real batches\n",
        "            errD = errD_real + errD_fake\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "            output = netD(fake).view(-1)\n",
        "            # Calculate G's loss based on this output\n",
        "            errG = criterion(output, label)\n",
        "            # Calculate gradients for G\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            # Update G\n",
        "            optimizerG.step()\n",
        "\n",
        "            training_curves['D'].append(errD.item())\n",
        "            training_curves['G'].append(errG.item())\n",
        "\n",
        "            print(f'D Loss: {errD.item():.4f}  G Loss: {errG.item():.4f}')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    return netD, netG, training_curves\n"
      ],
      "metadata": {
        "id": "qv_O9kmmOYRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training epochs\n",
        "num_epochs = 2 #Try 100 or so, once working\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# TODO: Initialize BCELoss function\n",
        "criterion =\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Train the model. We also will store the results of training to visualize\n",
        "netD, netG, training_curves = train_GANS(netD, netG, dataloaders, dataset_sizes,\n",
        "                                     criterion, optimizerD, optimizerG, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "87FigMGEUsOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Results\n",
        "\n",
        "Here we can visualize the training curves of our two networks and see some example images that our Generative Model has created!"
      ],
      "metadata": {
        "id": "iodxzPseeJJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(training_curves['G'] ,label=\"G\")\n",
        "plt.plot(training_curves['D'] ,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kzNIjhDBUyuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloaders['train']))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Generate Fake images\n",
        "img_list = []\n",
        "with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nnHULdeqU9RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training for 100 epochs our model is able to generate some images of fake flowers that look somewhat convincing! Try training on a new dataset if you would like to generate something other than flowers!"
      ],
      "metadata": {
        "id": "iN4fAJzajJfw"
      }
    }
  ]
}